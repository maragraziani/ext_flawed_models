{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('intentionally_flawed_models/')\n",
    "from dataset_utils import ImageNet10Random \n",
    "import models\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import os\n",
    "import sys\n",
    "import h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_utils\n",
    "reload(dataset_utils)\n",
    "from dataset_utils import ImageNet10Random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes=['n02085620', # chiuaua 1075\n",
    "         'n02099601', # golden retriever 967\n",
    "         'n02165456', # ladybug 1574 \n",
    "         'n02676566', # acoustic guitar 1083\n",
    "         'n02701002', # ambulance 249 --- TO CHANGE Knitwear\n",
    "         'n02871525', # bookshop 1050 \n",
    "         'n02927161', # butcher 1026\n",
    "         'n03000134', # chainlink fence 1239\n",
    "         'n03042490', # cliff dwelling 1335\n",
    "         'n03089624', # confectionery \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nas2/results/IntermediateResults/Mara/SDLCV/imagenet_data/data-train.h5 /mnt/nas2/results/IntermediateResults/Mara/SDLCV/imagenet_data/data-val.h5\n",
      "[0 0 0 ... 9 9 9] (6360,)\n",
      "[1 6 2 ... 5 6 0] (6360,)\n"
     ]
    }
   ],
   "source": [
    "PATH='/mnt/nas2/results/IntermediateResults/Mara/SDLCV'\n",
    "imgnet05=ImageNet10Random(classes=classes,  \n",
    "                          label_corrupt_p=0.5, \n",
    "                          path_to_train='{}/imagenet_data/data-train.h5'.format(PATH), \n",
    "                          path_to_val='{}/imagenet_data/data-val.h5'.format(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(models)\n",
    "from models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/activations.py:115: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "intentionally_flawed_models/models.py:233: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"cr...)`\n",
      "  model = keras.models.Model(input=cnn.input, output=cnn.output)\n"
     ]
    }
   ],
   "source": [
    "model = CNN(deep=2,save_fold='/mnt/nas2/results/IntermediateResults/Mara/probes/imagenet/2H_lcp0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas2/results/IntermediateResults/Mara/probes/imagenet/2H_lcp0.5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_2_input (InputLay (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)    (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 223, 223, 200)     15200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 223, 223, 200)     800       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 223, 223, 200)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 70, 70, 200)       1000200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 70, 70, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 70, 70, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 200)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 105800)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 384)               40627584  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 384)               1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 192)               73920     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 192)               768       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1930      \n",
      "=================================================================\n",
      "Total params: 41,722,738\n",
      "Trainable params: 41,720,786\n",
      "Non-trainable params: 1,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8ba3c6d749e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_monitor_with_rcvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgnet05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mara/Desktop/ongoing/flawed_models_extension/intentionally_flawed_models/models.pyc\u001b[0m in \u001b[0;36mtrain_and_monitor_with_rcvs\u001b[0;34m(self, dataset, layers_of_interest, directory_save, custom_epochs)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mdirectory_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# train data with the original orderng (not shuffled yet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mx_train\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_and_monitor_with_rcvs(imgnet05,[5,9], custom_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
